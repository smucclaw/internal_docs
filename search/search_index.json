{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome!","text":"<p>It's still in a pretty rough state, but hopefully it's enough to be helpful.</p>"},{"location":"#how-to-read-this","title":"How to read this","text":"<p>Start with the Historical Context, which links to the original grant proposal. (If you don't have access to our Google Drive, ask one of us for the proposal, or ask Meng for access to it).</p> <p>Then read this overview of the current L4 system. From there, it should be clear what to look at to get more information about the specific components of the system.</p> <p>Other noteworthy things include:</p> <ul> <li>a more detailed, but currently still WIP, discussion of the codebase in the Codebase section.</li> <li>an annotated bibliography in 'Further Reading'; this will be helpful for getting broader background on computational law and legal DSLs.</li> </ul>"},{"location":"#on-contributing","title":"On contributing","text":"<p>If you are writing something that involves explaining things, it'd probably be a good idea to get someone to at least skim it (i.e., 'code' review).</p>"},{"location":"#mkdocs-related","title":"MkDocs related","text":""},{"location":"#docs","title":"Docs","text":"<p>We're using Material for MkDocs, the documentation for which is available at https://squidfunk.github.io/mkdocs-material/.</p>"},{"location":"#commands-just-in-case","title":"Commands, just in case","text":"<ul> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"further_reading/","title":"Further reading","text":""},{"location":"further_reading/#relevant-prior-art","title":"Relevant Prior Art","text":"<p>Ordered in roughly chronological / introductory sequence</p> <ul> <li> <p>Ronald Lee: A Logic Model for Electronic Contracting, Candid</p> </li> <li> <p>Hvitved's PhD</p> </li> <li> <p>Camilleri's PhD</p> </li> <li> <p>Aarne Ranta, Translating between Language and Logic</p> </li> <li> <p>Model Checking Contracts, a case study</p> </li> <li> <p>Going Functional On Exotic Trades by Simon Frankau, Diomidis Spinellis, Nick Nassuphis, Christoph Burgard</p> </li> <li> <p>This feels to YM like what Meng's MathLang amounts to, in practice.</p> </li> <li> <p>Catala and related papers</p> </li> <li>Catala: a programming language for the law 2021</li> <li>Catala: Moving Towards the Future of Legal Expert Systems</li> <li>Formalizing Date Arithmetic and Statically Detecting Ambiguities for the Law</li> <li> <p>Sarah Lawsky 2017 A Logic for Statues (Lawsky is a law professor)</p> <ul> <li>\"This essay examines the structure of statutory reasoning after ambiguities are resolved and the meaning of the statute's terms established. It argues that standard formal logic is not the best approach for representing statutory rule-based reasoning. Rather, the essay argues, using the Internal Revenue Code and accompanying regulations, judicial decisions, and rulings as its primary example, that at least some statutory reasoning is best characterized as defeasible reasoning \u2014 reasoning that may result in conclusions that can be defeated by subsequent information \u2014 and is best represented using default logic.\"</li> </ul> </li> <li> <p>SLEEC / LEGOS: https://dl.acm.org/doi/abs/10.1145/3597503.3639093, https://github.com/NickF0211/LEGOs</p> </li> <li> <p>Christopher Clack's Past Projects: https://christopherclack.com/teaching</p> </li> <li> <p>Stipula</p> </li> <li> <p>Symboleo</p> </li> <li> <p>see the survey of legal DSLs section in https://drive.google.com/file/d/1--zBgq3Js0aMKMNoBjBC5wYmB3GcERR2/view?usp=drive_link</p> </li> <li> <p>DMN</p> </li> <li> <p>survey of the field as of about 2009: https://drive.google.com/file/d/12VIjnWOFDPa-mxAPH3_Lmynr0kWckE50/view?usp=drive_link Paul N Otto, Annie I. Anton, Managing Legal Texts in Requirements Engineering</p> </li> </ul>"},{"location":"further_reading/#on-the-structure-of-insurance-contracts-and-ux-for-apps-helping-people-understand-them","title":"On the structure of insurance contracts and UX for apps helping people understand them","text":""},{"location":"further_reading/#work-by-codex-at-stanford","title":"Work by CodeX at Stanford","text":"<ul> <li>https://codexstanford.github.io/formation-demo/ showcases an idealized, simplified insurance contract and its encoding in Prolog, as well as a web form for it (click on \"Switch to Claims Analysis\") This is helpful for seeing the abstract structure of most insurance contracts.</li> <li>https://royalsocietypublishing.org/doi/full/10.1098/rsta.2023.0160 is worth skimming. the arguments here are very quick, but there's some useful info here</li> <li>One of the authors of that paper also gave a short talk at this year's Future Law conference that had useful info on ideal UX for a web app that helps people answer questions about insurance contracts.</li> </ul>"},{"location":"further_reading/#other-compilations-of-readings-weve-amassed-over-the-years","title":"Other Compilations of readings we've amassed over the years","text":"<ul> <li> <p>https://github.com/smucclaw/complaw/tree/main/doc Introduction to computational law</p> </li> <li> <p>https://github.com/smucclaw/complaw/blob/main/doc/juniors/README.org the Juniors Readme</p> </li> </ul>"},{"location":"further_reading/#publications-by-team-members","title":"publications by team members","text":"<p>GOVERNATORI, Guido and WONG, Meng Weng (HUANG Mingrong). Defeasible semantics for L4. (2023). POPL ProLaLa 2023.</p> <p>OLIVIERI, Francesco; GOVERNATORI, Guido; CRISTANI, Matteo; ROTOLO, Antonino; and SATTAR, Abdul. Deontic meta-rules. (2023). Journal of Logic and Computation.</p> <p>WATT, Seng Joe; GOODENOUGH, Oliver; and WONG, Meng Weng (HUANG Mingrong). Deontics and time in contracts: An executable semantics for the L4 DSL. (2023). Legal Knowledge and Information Systems: Proceedings of JURIX 2023. 379, 119-124.</p> <p>BHUIYAN, Hanif; GOVERNATORI, Guido; MAHAJAN, Avishkar; RAKOTONIRAINY, Andry; and WONG, Meng Weng (HUANG Mingrong). Driving-decision making of autonomous vehicle according to Queensland overtaking traffic rules. (2022). International Workshop on AI Compliance Mechanism WAICOM 2022.</p> <p>MAHAJAN, Avishkar; STRECKER Martin; WATT, Seng Joe; and WONG, Meng Weng (HUANG Mingrong). Compliance through model checking. (2022). International Workshop on AI Compliance Mechanism WAICOM 2022.</p> <p>LIM, How Khang; MAHAJAR, Avishkar; STRECKER, Martin; and WONG, Meng Weng. Automating defeasible reasoning in law with answer set programming. (2022). ICLP 2022: Proceedings of the International Conference on Logic Programming 2022 Workshops: Haifa, Israel, 31 July - 1 August: Workshop on Goal-Directed Execution of Answer Set Programs 2nd GDE 2022, August 1. 1-11.</p> <p>MAHAJAN, Avishkar; STRECKER, Martin; and WONG, Meng Weng (HUANG Mingrong). User guided abductive proof generation for answer set programming queries. (2022). Proceedings of the 24th International Symposium on Principles and Practice of Declarative Programming, Tbilisi, Georgia, 2022 September 20-22. 1-14.</p> <p>RANTA, Aarne; LISTENMAA, Inari; SOH, Jerrold; and WONG, Meng Weng (HUANG Mingrong). An end-to-end pipeline from law text to logical formulas. (2022). Legal knowledge and information systems: Proceedings of the 35th International Conference, Saarbr\u00fccken, Germany, 2022 December 14-16. 362, 237-242.</p> <p>LISTENMAA, Inari; HANAFIAH, Maryam; CHEONG, Regina; and KALLBERG, Andreas. Towards CNL-based verbalization of computational contracts. (2021). CNL 2020/21 7th International Workshop in Controlled Natural Language: Workshop Proceedings, 2021, September 8-9. 1-7.</p> <p>MORRIS, Jason. Constraint answer set programming as a tool to improve legislative drafting. (2021). Proceedings of the 18th International Conference on Artificial Intelligence and Law, S\u00e3o Paulo, Brazil, 2021 June 21-25. 262-263.</p> <p>WONG, Meng Weng. Rules as code: Seven levels of digitisation. (2020). 1-24.</p>"},{"location":"future_aspirations/","title":"Future aspirations","text":"<p>See https://miro.com/app/board/uXjVKP7EJsM=/</p>"},{"location":"historical_context/","title":"History","text":"<p>It'll probably help to skim the original grant proposal --- if you have access to our Google Drive, click here or search for \"IAF Proposal (Part A)\".</p> <p>If you don't have access to it, feel free to ask one of us for it.</p>"},{"location":"historical_context/#prior-art","title":"Prior Art","text":"<p>For a snapshot of the field roughly as of 2020, see the smucclaw/complaw/doc readme: https://github.com/smucclaw/complaw/tree/main/doc.</p>"},{"location":"misc/","title":"Misc","text":"<p>TODO: Explain</p> <ul> <li>Some early ideas from YM re metadata</li> <li>Joe has also mentioned some ideas that'd be worth writing down</li> </ul>"},{"location":"current_system/","title":"Overview of the current system","text":"<p>As the current user-facing documentation puts it,</p> <p>while there is one generic L4 syntax, L4 really admits of different fragments, each with their own specialized semantics, corresponding to the various transpilers.</p> <p>We'll systematically discuss each of these dialects / transpilers and their statuses when we discuss the codebase in more detail. But before doing that, let's briefly survey what I (YM) take to be the most currently functional components of the L4 ecosystem --- or, to put it another way, what one can currently do with L4.</p> <p>To clarify, this page aims to introduce the L4 ecosystem by highlighting the the most interesting things that can be done with it, and its key dialects. It does not discuss in-the-weeds details about the codebases or their architecture --- see the Codebase section for that.</p> <p>Starting from a Natural4 encoding of a set of legal rules, you can automatically:</p> <ul> <li>parse the spreadsheet CSV into an internal representation: see codebase/natural4</li> <li>generate a web form \"expert system\" that interviews an end-user and returns a result.</li> <li>The simple version of this only deals with propositional logic.</li> <li>The Logical English version deals with numbers and dates too</li> <li>New infrastructure uses the mathlang codebase.</li> <li>visualize the simple Boolean decision logic, which is the subject of constitutive rules,</li> <li>as a black-and-white SVG ladder diagram</li> <li>as an interactive HTML widget</li> <li>visualize the state transition logic, which is the subject of regulative rules,</li> <li>as a Petri Net</li> <li>statically analyze the state transition logic</li> <li>using Maude</li> <li>test the rules against user-specified \"unit tests\" similar to Cucumber/Gherkin</li> <li>this is on the roadmap and has not yet been built yet</li> </ul>"},{"location":"current_system/#the-mathlang-system-and-transpiler","title":"The MathLang system and transpiler","text":"<p>The MathLang codebase is intended to produce a Javascript runtime suitable for in-browser execution of decision rules originally encoded in L4.</p> <p>See:</p> <ul> <li>The 'Explainable' codebase</li> <li>mathlang</li> <li>generic mathlang</li> </ul>"},{"location":"current_system/#natural-language-generation","title":"Natural Language Generation","text":"<p>The current codebase for NLG is in natural4/src/LS/NLP/NLG.hs, and the grammars it is based on are in natural4/grammars.</p> <p>The NLG codebase was used by the web form generation. The main goal was to convert the conditions in the rules into questions.</p> <p>For a longer description, see NLG.</p>"},{"location":"current_system/#status","title":"Status","text":"<p>This was in use for the PDPA use case and the Rodents and vermin demo, both from 2021/2022. In the insurance use case, we shifted to Logical English, and it didn't use the GF-based NLG at all.</p> <p>We have ambitions to restart the NLG efforts\u2014more in the dedicated page for NLG.</p>"},{"location":"current_system/#natural-l4-syntax-specification","title":"Natural L4 syntax specification","text":"<p>Finally, a specification of sorts of the Natural L4 syntax is available here.</p>"},{"location":"current_system/logicalenglish/","title":"The Logical English transpiler","text":"<p>The LE transpiler converts stuff written in the LE/Proglog fragment of L4 (see Joe's specification) into Logical English code. This can then be used for various other purposes; e.g., as the basis for a rule engine serving a web app.</p> <p>In the context of the insurance claim calculator web app, we also had a different transpiler that converts the data model for a web app into a collection of JSON Schemas. Although we used the two in tandem in that usecase, the two systems aren't coupled to each other: the JSON schema sub-system can in principle be used with other dialects of L4.</p> <p>Docs for this can be found on the user-facing doc site</p> <p>There are some ways in which the code for the transpiler could be cleaned up. But that work has been deferred for now, because it's not clear we want to be using this, going forward.</p>"},{"location":"current_system/logicalenglish/#historical-context","title":"Historical Context","text":""},{"location":"current_system/logicalenglish/#motivation","title":"Motivation","text":"<p>This was motivated by the 2023 use case with the insurance company.</p> <p>If memory serves me right, we went for this because</p> <ul> <li> <p>we thought that some form of logic programming would make for a good foundation for the system --- eg, it would be simple to extend it with facilities for abductive reasoning. (You could of course also do this with more work in Haskell.)</p> </li> <li> <p>Some of the designers/implementers of this dialect of L4 had a strong interest in logic programming.</p> </li> <li> <p>Logical English was especially convenient to build upon because it is a kind of CNL wrapper of Prolog -- it's basically Prolog with a natural-language-y facade. In that way, Logical English made it a lot easier to go from a CNL like Natural L4 to Prolog.</p> </li> <li> <p>Logical English was able to produce relatively nice, human-readable explanation trees that's nicer than what one would produce with a naive logging evaluator / backwards chainer that's written from scratch. This capability admittedly wasn't used in the end, but it seemed like a nice advantage at the outset, when it wasn't clear what kinds of explanations we might need.</p> </li> </ul>"},{"location":"current_system/logicalenglish/#reservations-people-had-about-this","title":"Reservations people had about this","text":"<p>Meng</p> <ul> <li> <p>did not like how it looked like we were piggybacking on another legal DSL (Logical English)</p> </li> <li> <p>did not like how the backend took longer than one might like (I cannot remember exactly how long) to handle requests. That said, YM and Joe would note that this is not a foundational issue but rather an engineering-level one --- it's something that can solved with some engineering effort.</p> </li> </ul> <p>YM also thinks, based in part on feedback from other members of the team, that the interfaces (in a software design sense) between the Logical English backend and the frontend / other callers could be improved and made more ergonomic. But this also is something that could probably be achieved with a reasonable amount of effort / time.</p> <p>One might also have some reservations about how working with, eg., Swi-Prolog and having the client be totally in-browser and adding in more advanced Q&amp;A functionality isn't trivial (though Joe has already worked this out).</p> <p>Ultimately, though, YM's personal opinion is that there's no reason to hang on to this if we're overhauling things from the ground up.</p>"},{"location":"current_system/logicalenglish/#lessons","title":"Lessons","text":"<ul> <li>For explainability, it might be enough, at least in the short run, to have some way, perhaps a DSL, for annotating with metadata the things we want to expose to downstream consumers, so that you can control what gets logged or 'explained', and maybe also the phrasing / how it gets explained.</li> <li>To put it another way, there is a prima facie tension between wanting an encoding that (i) is faithful to the original text / legalistic, more technical concerns and yet (ii) can support explanations that are couched in less legalistic language and more understandable to ordinary users. Metadata facilities might be a good enough way to solve this.</li> </ul>"},{"location":"current_system/logicalenglish/#status","title":"Status","text":"<p>We'll want to have this at least as a back up option, in case we don't have something else that can do at least as much when a usecase rolls around.</p> <p>We should maintain our LE codebase to continue to read LE-styled L4 and transpile to a rule engine that answers queries along the lines of the current API.</p> <ul> <li>If</li> <li>by the time we need to deliver a new use case,<ul> <li>we have a working rule engine that</li> <li>is sufficient for that use case</li> <li>and is a superset of what LE is capable of doing,</li> </ul> </li> <li>then we can retire the LE interface;</li> <li>else, we should do the engineering work needed to speed up the LE engine.</li> </ul> <p>Meng believes that if we encapsulate the single-goal-query orientation of the current protocol, to allow multiple queries encapsulated within one session, we can resolve the problem of outputting counterfactuals.</p>"},{"location":"current_system/other_experiments/","title":"Other experiments","text":"<p>A handful of other work done over the years, may be useful to future development.</p> <ul> <li>Joe's https://github.com/smucclaw/l4-lp</li> </ul> <p>This project formalises a semantics for L4, a legal DSL for the law, and implements a rule engine execution pipeline, along with various language binding libraries for interacting with L4 and the pipeline. Among these is a browser JS ESM library which is used to implement an IDE that parses, transpiles and executes L4, as well as visualise execution traces completely in the browser.</p> <ul> <li> <p>YM's simple Forge (Alloy-style specification language) formalization of PDPA</p> </li> <li> <p>Meng's DMN &lt;-&gt; MD</p> </li> <li> <p>L4Meta</p> </li> <li> <p>Jason Morris's experiments with SCASP</p> </li> </ul>"},{"location":"current_system/webforms/","title":"Web form generation","text":"<p>One useful thing you can do with L4 is to scaffold a web form app from an L4 specification.</p> <p>There have been two generations of this app builder.</p> <pre><code>graph TB;\n    classDef natural4exe fill:#f9f,stroke:#333,stroke-width:2px;\n\n    A[\"Google Sheets tab\"] -- \"L4/Refresh\" --&gt; B[[\"Apps Script Sanic Hello.py\\nsmucclaw/gsheet/natural4-server/\"]];\n    B -- calls --&gt;C[[\"natural4-exe (smucclaw/dsl/lib/haskell/natural4/\\napp/Main.hs)\"]];\n\n    C --\"runs\"--&gt; C1[\"the Purescript and Vue codebase\\n(2021/2022)\"];\n    C1--\"imports\"--&gt;D[[\"LS/XPile/Purescript.hs\"]];\n    D--\"transpiles to\"--&gt;E[(\"workdir/uuid/\\npurs/LATEST.purs\")];\n    E--\"consumed by\"--&gt;F[\"vue-json frontend\\n(smucclaw/vue-pure-pdpa)\"];\n\n    C --\"runs\"--&gt; G0[\"the JSON Schema transpiler\\n(2023)\"];\n    G0--\"imports\"--&gt;G1[[\"LS/XPile/ExportTypes.hs\"]];\n    G1--\"transpiles to\"--&gt;G2[(\"workdir/uuid/\\njsonTp/LATEST.json\")];\n    G2--\"consumed by\"--&gt;G3[\"react frontend\\n(smucclaw/usecases/smu)\"]</code></pre>"},{"location":"current_system/webforms/#propositional-logic-only-decision-support-web-app","title":"Propositional-logic-only decision support web app","text":"<p>(the Purescript and Vue codebase)</p> <p>The first generation builds a Vue web app that allows users to answer YES / NO questions to arrive at some sort of decision, and to see a visualization of that (see the discussion of ladder diagrams in Visualizations). The most involved example of this involved making such an app from an encoding of the Personal Data Protection Act.</p> <p>This is quite limited in its functionality: it only handles propositional logic.</p> <p>This app was internally titled \"Dolora, the Law Explorer\".</p>"},{"location":"current_system/webforms/#historical-context","title":"Historical Context","text":"<p>This was motivated by a 2021/2022 use case around the Personal Data Protection Act.</p>"},{"location":"current_system/webforms/#status","title":"Status","text":"<p>Still forms part of current demos; badly needs to be superseded.</p>"},{"location":"current_system/webforms/#visible-at","title":"Visible at","text":"<ol> <li>spreadsheet sidebar, at top.</li> <li>A static snapshot of the generated app is stable and available at https://smucclaw.github.io/mengwong/pdpa</li> </ol>"},{"location":"current_system/webforms/#more-sophisticated-web-form","title":"More sophisticated web form","text":"<p>Sometimes a Boolean expression is really an arithmetic inequality in disguise, like, \"is age &gt;= 21?\" so then we find it more natural to ask for \"age\". Or maybe we don't have to ask for it from the user, we look it up from some existing sidecar of JSON input retrieved from an enterprise database. Either way, though, we have something like a</p> <pre><code>    evaluatePredicate :: Expr Int -&gt; Expr Bool\n</code></pre> <p>Web forms have various forms of user input widgets to support this more expanded universe of expressions.</p> <p>In the 2023 insurance case we needed to capture dates and numbers in addition to basic Bools.</p> <p>The second generation tried to separate MVC layers by using an approach based on react-jsonschema-form / vue-form-json-schema.</p> <p>The relevant docs explain how the web form generation works in some detail. The JSON schema transpiler docs are also relevant.</p> <p>There was also an abortive attempt at trying to find a way to separate UI text from the web app.</p> <p>[TODO: Link to further discussions of the JSON Schema transpiler + Clojurescript client]</p>"},{"location":"current_system/webforms/#historical-context_1","title":"Historical Context","text":"<p>This was motivated by that use case with the insurance company.</p>"},{"location":"current_system/webforms/#status_1","title":"Status","text":"<p>Still relevant,</p> <ul> <li>though YM thinks that there's quite a bit that could be improved, especially with regards to the interfaces (in the software design sense).</li> <li>And ideally, we'd also want to re-examine the semantics of the schema definition constructs.</li> <li>The JSON Schema transpiler also needs some work. [TODO: Add more detail here on what kind of work]</li> </ul> <p>NOTE: The example form app repo needs some work. Haven't really bothered polishing it because we'll probably want to improve the web app generation system in more fundamental ways.</p>"},{"location":"current_system/codebase/","title":"Notes on the Codebase","text":"<p>Our codebase is split across multiple repos, and even within the <code>dsl</code> repo, across multiple <code>stack</code> projects under <code>lib/haskell/</code>.</p> <p>The major projects are:</p> <ul> <li>anyall a foundational representation of boolean structures (conjunctive and disjunctive lists + negation) augmented with labels</li> <li>explainable supports verbose evaluation of arithmetic and boolean expressions;  discussion of 'MathLang' is also housed here</li> <li>natural4 the compilation toolchain for the spreadsheet-based version of the L4 CNL</li> <li>usecases contains most of the work specific to the 2023 insurance case.</li> </ul> <p>We also talk about</p> <ul> <li>visualizations of boolean and arithmetic \"mathlang\" structures, and of state transitions as a petri net</li> </ul> <p>Please see the system architecture map to see how these code components work together.</p>"},{"location":"current_system/codebase/anyall/","title":"The AnyAll codebase","text":"<p>This codebase was carved out and implemented initially by johsi-k.</p> <p>It was meant to support boolean structures (\"BoolStructs\"), augmenting the basic \"and/or\", \"any/all\" operators over lists with some natural language decorations (\"PrePost labels\").</p> <p>It grew to support \"ladder logic\" visualization.</p> <p>What draws the diagrams?</p> <p>Well, it depends which diagram you mean. There are two families of diagrams.</p> <p>The original SVG ladder diagrams that show up in the sidebar are drawn by <code>SVGLadder.hs</code>. The sidebar shows tiny versions. They zoom to full-scale versions.</p> <p>Then there's another family of diagrams, used in the web-app interview. There, the clickable ladder diagrams that show up at the bottom of the page are drawn by the <code>ladder-diagram</code> repo described in visualizations.</p>"},{"location":"current_system/codebase/architecture/","title":"Overall 2023 System Architecture Diagram","text":"<pre><code>graph TB;\n    classDef natural4exe fill:#f9f,stroke:#333,stroke-width:2px;\n\n    A[\"Google Sheets tab\"] -- \"L4/Refresh\" --&gt; B[[\"Apps Script Sanic Hello.py\\nsmucclaw/gsheet/natural4-server/\"]];\n    B -- calls --&gt;C[[\"natural4-exe (app/Main.hs)\"]];\n\n    C --\"runs\"--&gt; C1[\"the Purescript and Vue codebase\\n(2021/2022)\"];\n    C1--\"imports\"--&gt;D[[\"LS/XPile/Purescript.hs\"]];\n    D--\"transpiles to\"--&gt;E[(\"workdir/uuid/\\npurs/LATEST.purs\")];\n    E--\"consumed by\"--&gt;F[\"vue-json frontend\\n(smucclaw/vue-pure-pdpa)\"];\n\n    C --\"runs\"--&gt; G0[\"the JSON Schema transpiler\\n(2023)\"];\n    G0--\"imports\"--&gt;G1[[\"LS/XPile/ExportTypes.hs\"]];\n    G1--\"transpiles to\"--&gt;G2[(\"workdir/uuid/\\njsonTp/LATEST.json\")];\n    G2--\"consumed by\"--&gt;G3[\"react frontend\\n(smucclaw/usecases/smu)\"]\n\n    subgraph H1 [\"svg generator\"]\n      H1A[[\"LS/XPile/SVG.hs\"]];\n      H1A--\"imports\"--&gt;H1B[[\"AnyAll.makeSvg\\n(dsl/lib/haskell/anyall)\"]];\n    end\n\n    C --\"runs\"--&gt; H0[\"the simple Boolean circuit visualizer\"]\n    H0--\"imports\"--&gt; H1\n    H1--\"transpiles to\"--&gt;H2[(\"workdir/uuid/\\naasvg/LATEST/*.svg\")];\n    H2--\"consumed by\"--&gt;H3[\"spreadsheet sidebar\\n(smucclaw/gsheet)\"]\n\n    F --\"becomes\"--&gt; F1[\"javascript data structure\\nQoutJS\"]\n    F1--\"consumed by\"--&gt;F2[\"LadderDiagram.vue\"]\n    F2--\"imports\"--&gt;F4[\"the interactive ladder diagram generator\\nladder-diagram js library\\n/src/smucclaw/ladder-diagram\"]\n\n    C --\"runs\"--&gt;J1[\"Logical English transpiler\"]\n    J1 --\"imports\"--&gt;J2[\"LS/XPile/LogicalEnglish.hs\"]\n\n    J2--\"transpiles to\"--&gt;J3\n\n    subgraph J3 [\"logical english format\"]\n        J3a[(\"workdir/uuid/\\nlogical_english/LATEST.le\")]\n        J3a--\"copied to\"--&gt;J3b[(\"smucclaw/usecases/smu/\\npublic/le/program.le\")]\n    end\n\n    J3--\"consumed by\"--&gt;J4[\"LE wrapper\"]\n    J4--\"passed once for each query against\"--&gt;J5[\"Logical English Prolog Pengines server\"]\n    G3--\"calls\"--&gt;J5\n\n    C --\"transpiles to\"--&gt;K[\"Prolog\\n(obsolete)\"]\n    C --\"transpiles to\"--&gt;L[\"future targets\\nPython API Backend\\nJavascript for browser-side\\nGo libraries\"]\n    C --\"transpiles to\"--&gt;Z[\"other transpilers\\nnot detailed at this time\"]\n</code></pre> <p>If the \"other transpilers not detailed at this time\" need to be detailed, please edit the diagram above accordingly.</p>"},{"location":"current_system/codebase/baby_L4/","title":"Baby L4 -- a precursor to Natural L4","text":"<p>In 2020/2021, first came the BNFC-based L4 https://github.com/smucclaw/dsl/tree/main/bnfc</p> <p>In 2021/2022, we tried to separate out a core language. We called it core-l4, or baby-l4. That effort is recorded at https://github.com/smucclaw/baby-l4</p> <p>In 2022/2023, we brought up the natural4 toolchain.</p> <p>In 2024 we started thinking about going back to basics with a BNF-based grammar again.</p>"},{"location":"current_system/codebase/devops/","title":"DevOps","text":"<p>When we deliver a use case, the runtimes need to be exposed for third-party use, and maintained against bitrot.</p> <p>We use AWS for this. We have the insurance LE backend server running in a production instance somewhere.</p> <p>The PDPA vue server also runs in a production instance.</p> <p>https://l4-documentation.readthedocs.io/en/23.06.04/docs/links-backend.html</p> <p>Docs for how to set up some of the Natural L4 server-side stuff</p> <p>We separate dev from production servers. There is a dev server that is available for people to work on, if their laptops aren't sufficient. Access to this server is controlled by IP for reasons best explained by the university IT department, so every time you want to log in to it, you have to ask somebody who has AWS console credentials to go update the security group ACL.</p>"},{"location":"current_system/codebase/explainable/","title":"The 'Explainable' codebase","text":"<p>The Explainable codebase includes the following components.</p> <ul> <li>MathLang: a DSL for arithmetic expressions and predicates</li> <li>Explainable: a monad for evaluating MathLang expressions and providing explanations for the (intermediate and final) results</li> </ul> <p>These components of the Explainable codebase were intended to:</p> <ul> <li>illustrate an evaluation-tree approach to logging computation for explainability purposes; and</li> <li>provide a parallel implementation of infrastructure to support the insurance use case in 2023.</li> </ul>"},{"location":"current_system/codebase/explainable/#on-mathlang","title":"On 'MathLang'","text":"<p>To head off potential confusion right away: 'MathLang' can refer to several things:</p> <ul> <li>some kind of functional programming based DSL</li> <li>the specific embedded DSL Meng had created during the insurance usecase for his own experimentation and testing, and that was not wired up to the L4 codebase</li> <li>the version of that that Inari and YM worked on, and that is wired up to the wider L4 codebase</li> </ul> <p>These will be further explained in due course.</p>"},{"location":"current_system/codebase/explainable/#historical-context","title":"Historical Context","text":"<p>Let's start with: Why 'MathLang', when we already had the Logical English dialect? Recall that Meng did not like how the Logical English backend had been slow in its handling of requests, and that he had preferred a more functional approach to encoding contracts.</p> <p>During the insurance usecase, Meng had written an embedded DSL, and wanted that to be further developed (hence the work that Inari and YM did). In particular, he wanted something like that that could compute things and give traces for its computations, and crucially, do it fast.</p> <p>While the primary codepaths for the insurance use case ran with L4 and Logical English, this Explainable codebase allowed Meng to experiment with alternative formulations, and to do \"cleanroom testing\" of the primary codebase.</p> <p>Interestingly, this codebase features twin implementations in Haskell and Typescript, with working runtimes in both languages.</p> <p>We wanted a Typescript runtime so that the computations could run in the end-user's browser.</p>"},{"location":"current_system/codebase/explainable/#further-links-references","title":"Further links / references","text":"<p>See also:</p> <ul> <li>https://github.com/smucclaw/usecases/blob/main/sect10-typescript/</li> <li>'lower-level' docs on 'generic mathlang'</li> <li>'lower-level' docs on 'mathlang'</li> </ul> <p>Links to Meng's embedded DSL:</p> <ul> <li>The Haskell embedded DSL</li> <li>For comparison: Natural L4 version of the rules PAU0 and PAU4</li> <li>The Haskell types and runtime</li> <li>The TS output pretty-printed from Haskell)</li> <li>The TS runtime which evaluates the TS output</li> </ul> <p>That embedded DSL should give you some sense for what Meng has in mind with his 'MathLang'.</p>"},{"location":"current_system/codebase/explainable/#use","title":"Use","text":"<p>In 2023, the \"business logic\" of the use case was independently encoded in Haskell and then pretty-printed to Typescript for evaluation.</p> <pre><code>\ngraph TB;\n\n    classDef tsruntime fill:#9ff,stroke:#333;\n\n    A1[\"ToMathLang.hs\\n(usecases/sect10-haskell/src/)\"]\n\n    A1 -- \"imports\" --&gt; B;\n    B[\"Explainable/MathLang.hs\"]\n\n    A1 -- \"defines\" --&gt; A2[\"user-space decision logic\\n(in internal DSL)\"]\n\n    A2 -- \"has type\" --&gt; A3[\"Explainable.MathLang.Expr\"];\n\n    A3 -- \"can be natively evaluated by\" --&gt;B\n\n    B -- \"pretty-prints Exprs to\" --&gt;C[\"Typescript output\\n(sect10-typescript/src/\\npau.ts)\"]\n\n    C -- \"imports\" --&gt;D[\"mathlang.ts\\n(sect10-typescript/src/\\nmathlang.ts)\"]\n\n    F[\"The Abstract MathLang Language\"]\n    D -- \"implements\\nin Typescript\" --&gt;F\n    B -- \"implements\\nin Haskell\"    --&gt;F\n\n    C -- \"imported by\" --&gt;G[\"crunch.ts\\n(sect10-typescript/src/crunch.ts)\"]\n\n    G -- \"outputs to\" --&gt;H[\"sect10-typescript/\\ntests/\\ndot/\"]\n\n    class C,G,H,D tsruntime</code></pre> <p>All the above is orchestrated by a <code>Makefile</code> under <code>sect10-typescript</code>.</p> <p>Note that the business logic was independently encoded in the internal MathLang DSL and was not wired up to read from the Natural4 spreadsheets. As a clean-room re-implementation, that's fine, but in the long run, the DRY principle suggests that future MathLang toolchains should read from the spreadsheet or whatever natural4 encoding is canonical, rather than a reimplementation in <code>ToMathLang.hs</code>.</p> <p>(YM's note: the above discussion is about Meng's 'internal MathLang DSL' (i.e., his embedded DSL). This is different from the MathLang codebase that Inari and YM had worked on. The latter does work off the output from the Natural L4 parser.)</p>"},{"location":"current_system/codebase/explainable/#generic-mathlang-vs-mathlang","title":"'Generic MathLang' vs 'MathLang'","text":"<p>The term 'MathLang' is used in a couple of different ways. On the broadest sense, MathLang is supposed to be some kind of functional programming language. But there are also more specific senses; for example, it could also refer to the specific embedded DSL Meng had whipped up (see above) --- a DSL that departs from a more 'generic' / 'undergrad-textbook' functional programming language in some ways that make the translation to it more effortful.</p> <p>It is in this context that 'Generic MathLang' should be understood. Because the specific embedded-in-Haskell DSL that Meng had whipped up was</p> <ol> <li> <p>was written in a way that was hard to understand (I think Joe has been working on improving the code quality, though) and</p> </li> <li> <p>departs from a more 'generic' / 'undergrad-textbook' functional programming language in some ways that make the translation to it more effortful --- indeed, unnecessarily effortful, given the ostensible mandate ('get some kind of lambda calculus based thing out asap')</p> </li> </ol> <p>YM decided to first translate the output from the Natural L4 parser to an intermediate representation that he called Generic MathLang --- an intermediate representation that amounted to more generic, untyped lambda-calculus-looking AST --- before further translating it to other formats. That is, the envisioned pipeline was something like</p> <pre><code>Natural L4 parser =&gt; Generic MathLang =&gt; (e.g.) serialization of Generic MathLang for an in-browser interpreter | Meng's MathLang | ...etc\n</code></pre> <p>Doing this allows us, not only to (in principle) get a lot more quickly to a working web form backed by an in-browser interpreter (because, again, serializing Generic MathLang and then writing an in-browser interpreter with tracing would be a lot faster than having to read and test Meng's code carefully), but also improves code reuse, since we now have a lambda-calculus-y intermediate representation that we can work from if we need to experiment with producing other MathLang variants.</p> <p>YM had started implementing this over Dec 2023 - Jan 2024, but subsequently passed the baton on to Inari.</p> <p>This was admittedly YM's own understanding of Generic MathLang, but YM sees that Inari seems to also have stuck to this understanding of Generic MathLang; see her docs on the Generic MathLang codebase.</p>"},{"location":"current_system/codebase/explainable/#mengs-diagram-of-the-architecture","title":"Meng's diagram of the architecture","text":"<pre><code>graph TB;\n    A1[\"Google Sheets tab\\n(via API)\"] -- \"L4/Refresh\" --&gt; C;\n    A2[\"command-line invocation\\n(perhaps involving fswatch)\"] -- calls --&gt; C;\n    classDef highlight fill:#f9f,stroke:#333,stroke-width:2px;\n\n    subgraph C [\"natural4-exe (app/Main.hs)\"]\n        Parser --&gt; Interpreter;\n    end\n\n    C --\"runs\"--&gt; C1[\"the Generic MathLang codebase\\n(2024)\"];\n\n    C1--\"imports\"--&gt;D[[\"LS/XPile/MathLang\"]];\n    C1--\"imports\"--&gt;F\n\n    D--\"transpiles to\"--&gt;E[(\"workdir/uuid/\\nmathlangGen\\nmathlangTS\")];\n    class C1,D,E highlight;\n\n    classDef tsruntime fill:#9ff,stroke:#333;\n\n    E--\"hopefully somehow\\nbackward-compatible with\"--&gt;F[\"Explainable/MathLang.hs\"];\n\n    F --\"which takes it the rest of the way to\"--&gt;G[\"the Typescript runtime\"]\n class F,G tsruntime</code></pre>"},{"location":"current_system/codebase/explainable/#types","title":"Types","text":"<pre><code>type ExplainableIO  r st a = RWST         (HistoryPath,r) [String] st IO (a,XP)\ntype Explainable    r st a = ExplainableIO r st a\n</code></pre>"},{"location":"current_system/codebase/explainable/#evaluation","title":"Evaluation","text":"<p>See the Explainable README.</p>"},{"location":"current_system/codebase/generic_mathlang/","title":"Generic MathLang","text":"<p>Generic MathLang is meant to be an intermediate step between the Rule datatype and MathLang. See also the high-level discussion of 'Generic MathLang' vs 'MathLang' in the discussion of the Explainable codebase.</p> <p>Things that get more structured from Rule. A lot of things in Rule are just free text inside a <code>MTExpr</code>, but it gets parsed in Generic MathLang.</p>"},{"location":"current_system/codebase/generic_mathlang/#arithmetic-expressions","title":"Arithmetic expressions","text":"<p>In Rule, a single cell may contain arbitrary expressions. Compare lines 1 and 2:</p> <pre><code>SUM,foo,bar,,,,,,, (1)\n,,,,,,,,,\nfoo + bar,,,,,,,,, (2)\n</code></pre> <p>Version (1) is parsed as an arithmetic expression in Rule, but version (2) is just free text. Generic MathLang parses everything it can, even inside the cells.</p>"},{"location":"current_system/codebase/generic_mathlang/#records","title":"Records","text":"<p>Text like <code>foo's,bar's,baz</code> gets parsed into records: <code>foo.bar.baz</code>.</p>"},{"location":"current_system/codebase/generic_mathlang/#functions","title":"Functions","text":"<p>Rule may define functions as follows (see example spreadsheet for larger context):</p> <pre><code>GIVEN x   IS A Number\n        y   IS A Number\nDECIDE x discounted by  y IS x * (1 - y)\n</code></pre> <p>And we can apply the function (simplified the arguments):</p> <pre><code>DECIDE Answer IS firstArg discounted by   secondArg\n</code></pre> <p>When parsed into rules, we don't have much structure:</p> <pre><code>HC { hHead = RPConstraint\n            [ MTT \"x\", MTT \"discounted by\", MTT \"y\" ] RPis\n            [ MTT \"x * (1 - y)\" ]\n   , hBody = Nothing}\n\nHC { hHead = RPConstraint\n            [ MTT \"Answer\" ] RPis\n            [ MTT \"firstArg\"\n            , MTT \"discounted by\"\n            , MTT \"secondArg\" ]\n   , hBody = Nothing}\n</code></pre> <p>The definition becomes as follows:</p> <pre><code>( \"discounted by\",\n        (\n            [ MkVar \"x\", MkVar \"y\" ], MkExp\n            { exp = ENumOp\n                { numOp = OpMul, nopLeft = MkExp\n                    { exp = EVar\n                        { var = MkVar \"x\" }, md = [{- omitted some metadata: line number, type etc. -}]\n                    }, nopRight = MkExp\n                    { exp = ENumOp\n                        { numOp = OpMinus, nopLeft = MkExp\n                            { exp = ELit\n                                { lit = EInteger 1 }, md = [{- omitted some metadata -}]\n                            }, nopRight = MkExp\n                            { exp = EVar\n                                { var = MkVar \"y\" }, md = [{- omitted some metadata -}]\n                            }\n                        }, md = [{- omitted some metadata -}]\n                    }\n                }, md = [{- omitted some metadata -}]\n            }\n        )\n    )\n</code></pre> <p>And the application as follows:</p> <pre><code>EVarSet\n    { vsetVar = MkExp\n        { exp = EVar { var = MkVar \"Answer\" }, md = [] }, arg = MkExp\n        { exp = EApp\n            { func = MkExp\n                { exp = EApp\n                    { func = MkExp\n                        { exp = EVar\n                            { var = MkVar \"discounted by\" }, md = [{- omitted some metadata -}]\n                        }, appArg = MkExp\n                        { exp = EVar\n                            { var = MkVar \"Step 3\" }, md = [{- omitted some metadata -}]\n                    }, md = []\n                }, appArg = MkExp\n                { exp = ERec\n                    { fieldName = MkExp\n                        { exp = EVar\n                            { var = MkVar \"risk cap\" }, md = [{- omitted some metadata -}]\n                        }, recName = MkExp\n                        { exp = EVar\n                            { var = MkVar \"accident\" }, md = [{- omitted some metadata -}]\n                        }\n                    }, md = []\n                }\n            }, md = []\n        }\n    }\n</code></pre>"},{"location":"current_system/codebase/generic_mathlang/#types","title":"Types","text":""},{"location":"current_system/codebase/mathlang/","title":"MathLang","text":"<p>Hornlikes from Rule can be transformed into MathLang expressions. AFAIK there's no attempt to transform other rule types (regulative, constitutive, \u2026).</p>"},{"location":"current_system/codebase/mathlang/#types","title":"Types","text":"<p>The core of MathLang is the following <code>Expr</code> type (reordered here, but all constructors are shown).</p> <pre><code>type ExprLabel = Maybe String\ndata Expr a =\n-- I think these are the most relevant constructors\n      Val      ExprLabel a                            -- ^ simple value\n    | MathBin  ExprLabel MathBinOp (Expr a) (Expr a)  -- ^ binary arithmetic operation\n    | MathVar            String                       -- ^ variable reference\n    | MathSet            String    (Expr a)           -- ^ variable assignment\n    | MathITE  ExprLabel  (Pred a) (Expr a) (Expr a)  -- ^ if-then-else\n    | ListFold ExprLabel SomeFold (ExprList a)        -- ^ fold a list of expressions into a single expr value\n\n-- These I find less important / could probably be restructured?\n    | Parens   ExprLabel           (Expr a)           -- ^ parentheses for grouping (??? why is this needed)\n    | MathMax  ExprLabel           (Expr a) (Expr a)  -- ^ max of two expressions (ListFold covers this)\n    | MathMin  ExprLabel           (Expr a) (Expr a)  -- ^ min of two expressions       \"\n    | MathApp  ExprLabel String [String] (Expr a)     -- ^ kind of a hack to allow for function to call another function etc. This constructor is removed in final result and the functions are inlined.\n    | Undefined ExprLabel -- ^ looks like a quick workaround after realizing there should be a way to recover from failure?\n</code></pre> <p>There's also similar structure for predicates.</p> <pre><code>-- | conditional predicates: things that evaluate to a boolean\ndata Pred a\n  = PredVal  ExprLabel Bool\n  | PredNot  ExprLabel (Pred a)                       -- ^ boolean not\n  | PredComp ExprLabel Comp (Expr a) (Expr a)         -- ^ Ord comparisions: x &lt; y\n  | PredBin  ExprLabel PredBinOp (Pred a) (Pred a)    -- ^ predicate and / or / eq / ne\n  | PredVar  String                                   -- ^ boolean variable retrieval\n  | PredSet  String (Pred a)                          -- ^ boolean variable assignment\n  | PredITE  ExprLabel (Pred a) (Pred a) (Pred a)     -- ^ if then else, booleans\n  | PredFold ExprLabel AndOr (PredList a)             -- ^ and / or a list\n</code></pre> <p>Both expressions and predicates have list versions. PredList is just a type alias, ExprList has constructors for maps, filters etc. There's <code>MathSection</code> for partially applying binary functions, for the purpose of mapping over <code>ExprList</code>.</p> <pre><code>type PredList a = [Pred a]\n\n-- | We can filter, map, and mapIf over lists of expressions. Here, @a@ is pretty much always a @Double@.\ndata ExprList a\n  = MathList  ExprLabel [Expr a]                                    -- ^ a basic list of `Expr` expressions\n  | ListMap   ExprLabel (MathSection a)               (ExprList a) -- ^ apply the function to everything\n  | ListFilt  ExprLabel                 (Expr a) Comp (ExprList a) -- ^ eliminate the unwanted elements\n  | ListMapIf ExprLabel (MathSection a) (Expr a) Comp (ExprList a) -- ^ leaving the unwanted elements unchanged\n  | ListConcat ExprLabel [ExprList a] -- ^ [[a]] -&gt; [a]\n  | ListITE    ExprLabel (Pred a) (ExprList a) (ExprList a)        -- ^ if-then-else for expr lists\n\ndata MathSection a\n  = Id\n  | MathSection MathBinOp (Expr a)\n\ndata MathBinOp = Plus | Minus | Times | Divide | Modulo\n</code></pre>"},{"location":"current_system/codebase/mathlang/#pipeline","title":"Pipeline","text":"<ol> <li>Spreadsheet gets parsed into a Rule</li> <li>Rule (only Hornlike) gets transformed into Generic MathLang</li> <li>Generic MathLang is transformed into MathLang.</li> </ol>"},{"location":"current_system/codebase/natural4/","title":"The Natural L4 codebase","text":""},{"location":"current_system/codebase/natural4/#ast-cst","title":"AST / CST","text":"<ul> <li>The <code>Rule</code> data structure</li> </ul>"},{"location":"current_system/codebase/natural4/#the-natural-l4-parser","title":"The Natural L4 parser","text":"<p>The first-generation parser was based on BNFC: see</p> <ul> <li>https://github.com/smucclaw/baby-l4/blob/main/l4.bnfc</li> <li>https://bnfc.digitalgrammars.com/</li> </ul> <p>This work was done around 2020, 2021. It parsed text-file input.</p> <p>The second-generation parser for the spreadsheet syntax was based on Megaparsec: see</p> <p>https://github.com/smucclaw/dsl/blob/main/lib/haskell/natural4/src/LS/</p> <p>The monadic parser is slow. Profiling it with a flame graph shows that a great deal of time is spent backtracking. The parser does a bunch of lookahead and other work to deal with indentation. BNFC has native support for \"layout rule\" logic. In this parser, we hacked up an emulation of indentation-as-parenthesis, which doesn't work very well. There is also a homegrown tracing engine that spits out megabytes of logging info to help figure out what the parser is thinking.</p> <p>Many test cases later, we still don't have full confidence in the parsing. For example, trying to set up a <code>BoolStructR</code> that has a non-null <code>PrePost</code> label can sometimes fail unintuitively when there is too much space or not enough space between the label and the children.</p> <p>The parser also hoists inline rules into top-level rules. This is the purpose of operating the parser within a Writer monad. See tellIDFirst.</p>"},{"location":"current_system/codebase/natural4/#mengs-analyzer-interpreter","title":"Meng's Analyzer / 'Interpreter'","text":"<p>After the input CSV is parsed into a collection of <code>Rule</code> types, Interpreter.hs attempts to analyze and reorganize it, to make it more ready for the various transpilers to export from.</p> <p>This is where rule substitution happens and simple rule rewriting/optimization.</p> <p>This module is not really an interpreter. It should have been called an Analyzer.</p> <pre><code>\ngraph TB;\n    A1[\"Google Sheets tab\\n(via API)\"] -- \"L4/Refresh\" --&gt; C;\n    A2[\"command-line invocation\\n(perhaps involving fswatch)\"] -- calls --&gt; C;\n    subgraph C [\"natural4-exe (app/Main.hs)\"]\n    classDef nl4exe fill:#f9f,stroke:#333,stroke-width:2px;\n\n P[\"src/LS/\\nParser.hs\"] --&gt; I[\"src/LS/\\nInterpreter.hs\"];\n class P,I nl4exe\n\n    end\n\n    C --\"runs\"--&gt; D[\"various transpilers under src/LS/XPile/\"];\n    D --\"output to\"--&gt;E[(\"workdir/uuid/\\nvarious LATEST files\")];</code></pre>"},{"location":"current_system/codebase/natural4/#module-dependency-graph","title":"Module dependency graph","text":"<p>produced by</p> <pre><code>(base) \u250c\u2500[20240522-14:35:55]   [mengwong@rosegold:~/natural4/src/LS]\n\u2514\u2500[0] &lt;git:(main a0ecd7ff) &gt; grep 'import LS' *.hs | grep -v -- '-- import' |  perl -ple 's/ \\(.*//g; s/\\.hs:import LS\\.(.+)/ --&gt; $1;/'\n</code></pre> <pre><code>graph TD;\n    classDef default fill:#f9f,stroke:#333;\n\n        Parser --&gt; Interpreter;\n\n      BasicTypes --&gt; TokenTable;\n      DataFlow --&gt; Rule;\n      DataFlow --&gt; Types;\n      DataFlow --&gt; XPile.Logging;\n      Error --&gt; BasicTypes;\n      Error --&gt; Utils;\n      PrettyPrinter --&gt; Rule;\n      PrettyPrinter --&gt; Types;\n      TokenTable --&gt; Utils;\n      Types --&gt; BasicTypes;\n      Types --&gt; Utils;\n      Verdict --&gt; Rule;\n\n      Lib --&gt; Error;\n      Lib --&gt; Parser;\n      Lib --&gt; RelationalPredicates;\n      Lib --&gt; Rule;\n      Lib --&gt; Tokens;\n      Lib --&gt; Types;\n      Lib --&gt; Utils;\n\n\n      RelationalPredicates --&gt; Parser;\n      RelationalPredicates --&gt; Rule;\n      RelationalPredicates --&gt; Tokens;\n      RelationalPredicates --&gt; Types;\n      RelationalPredicates --&gt; Utils;\n\n      Tokens --&gt; Error;\n      Tokens --&gt; Rule;\n      Tokens --&gt; Types;\n\n      Rule --&gt; Types;\n      Rule --&gt; XPile.Logging;\n\n      Parser --&gt; Rule;\n      Parser --&gt; Tokens;\n      Parser --&gt; Types;\n\n      Interpreter --&gt; PrettyPrinter;\n      Interpreter --&gt; RelationalPredicates;\n      Interpreter --&gt; Rule;\n      Interpreter --&gt; Types;\n      Interpreter --&gt; Utils;\n      Interpreter --&gt; XPile.Logging;</code></pre>"},{"location":"current_system/codebase/natural4/#detailed-function-call-graph","title":"Detailed function call graph","text":"<p>To produce this, run function-call-graph</p> <pre><code>(base) \u250c\u2500[20240522-14:28:22]   [mengwong@rosegold:~/natural4/src/LS]\n\u2514\u2500[0] &lt;git:(main a0ecd7ff) &gt; fcall --clusters Lib.hs Parser.hs Utils.hs  Interpreter.hs RelationalPredicates.hs Rule.hs Tokens.hs Types.hs   &gt; LS.dot\n(base) \u250c\u2500[20240522-14:29:42]   [mengwong@rosegold:~/natural4/src/LS]\n\u2514\u2500[0] &lt;git:(main a0ecd7ff) &gt; dot -Tsvg LS.dot &gt; LS.svg\n</code></pre> <p></p>"},{"location":"current_system/codebase/natural4/#transpilers","title":"Transpilers","text":"<p>Moving past the parser and analyzer stages, we come to the transpilers.</p> <pre><code>graph TB;\n    A1[\"Google Sheets tab\\n(via API)\"] -- \"L4/Refresh\" --&gt; C;\n    A2[\"command-line invocation\\n(perhaps involving fswatch)\"] -- calls --&gt; C;\n\n    subgraph C [\"natural4-exe (app/Main.hs)\"]\n classDef nl4exe fill:#f9f,stroke:#333,stroke-width:2px;\n\n Parser --&gt; Interpreter;\n class Parser,Interpreter nl4exe\n    end\n\n    C --\"runs\"--&gt; C1[\"the Purescript and Vue codebase\\n(2021/2022)\"];\n    C1--\"imports\"--&gt;D[[\"LS/XPile/Purescript.hs\"]];\n    D--\"transpiles to\"--&gt;E[(\"workdir/uuid/\\npurs/LATEST.purs\")];\n\n    C --\"runs\"--&gt; G0[\"the JSON Schema transpiler\\n(2023)\"];\n    G0--\"imports\"--&gt;G1[[\"LS/XPile/ExportTypes.hs\"]];\n    G1--\"transpiles to\"--&gt;G2[(\"workdir/uuid/\\njsonTp/LATEST.json\")];\n\n    C --\"runs\"--&gt; H0[\"the Prolog transpiler\"];\n    H0--\"imports\"--&gt;H1[[\"LS/XPile/Prolog.hs\"]];\n    H1--\"transpiles to\"--&gt;H2[(\"workdir/uuid/\\njsonTp/LATEST.json\")];\n\n    C --\"runs\"--&gt; I0[\"other transpiler\"];\n    I0--\"imports\"--&gt;I1[[\"LS/XPile/OtherTranspiler.hs\"]];\n    I1--\"transpiles to\"--&gt;I2[(\"workdir/uuid/\\nTranspilerDir/LATEST\")];</code></pre> <p><code>Main.hs</code> runs a whole zoo of transpilers:</p> <ul> <li>https://github.com/smucclaw/dsl/blob/main/lib/haskell/natural4/app/Main.hs#L185-L224</li> <li>https://github.com/smucclaw/dsl/tree/main/lib/haskell/natural4/src/LS/XPile</li> </ul> <p>We have already talked about some of these, above -- MathLang and Petri.</p> <p>TODO: Catalogue as many of the things as possible in https://github.com/smucclaw/dsl/tree/main/lib/haskell/natural4/src/LS/XPile and note their statuses and contexts, since that's what WT had asked for.</p>"},{"location":"current_system/codebase/natural4/#intro-xhs","title":"Intro-x.hs","text":"<p>The files:</p> <p>IntroBase.hs, IntroBasic.hs, IntroLog.hs, IntroReader.hs, IntroShoehorn.hs, IntroTrivial.hs</p> <ul> <li>Status: Tutorial, ready to be deprecated</li> <li>Context: These were written by Meng; they were intended to introduce the notion of transpilation and the patterns of implementation in this project. One pattern was about outputting to files on disk in various <code>Show</code>able or printable ways analogous to <code>STDOUT</code> and <code>STDERR</code>. Anotehr pattern has to do with logging. Not all the actual transpilers follow the structure outlined in these files, however, because some of the structure is quite specific to Meng's preferences and setup (e.g. the choice of logging framework). See also the discussion in the Logical English transpiler sub-section for why not all the transpilers use Meng's 'Interpreter'/'Analyzer'.</li> </ul>"},{"location":"current_system/codebase/natural4/#to-prolog-prologhs","title":"To Prolog (Prolog.hs)","text":"<ul> <li>Status: Deprecated</li> <li>Context: According to Meng (16 May), he had written this as a way of thinking through the semantics of L4. The thought was apparently to get a translational semantics for L4 by working out what the corresponding Prolog should be.</li> <li>YM: In any case, even if you wanted to go to Prolog, the Logical English transpiler would probably be a better way of doing that.</li> </ul>"},{"location":"current_system/codebase/natural4/#logical-english","title":"Logical English","text":"<p>I'll briefly note some in-the-weeds decisions about the implementation here (see the system overview for a more high-level discussion).</p> <p>Re Meng's Analyzer / 'Interpreter':</p> <ul> <li>This does not use the output from Meng's Analyzer / 'Interpreter'. Instead, it starts from the output from the parser.</li> <li>This is because</li> <li>(i) it wasn't clear that the semantics that was implicit in Meng's Analyzer / 'Interpreter' was something that would be compatible with that for this fragment of L4.</li> <li>(ii) it looked from a quick glance like some of the transformations that the analyzer/interpreter was doing might be lossy, e.g. there's some substitution or inlining</li> <li>(iii) it wasn't clear what the specification for Meng's Analyzer / 'Interpreter' was; and in particular, what assumptions and guarantees it was making or providing.</li> </ul> <p>It's also worth mentioning that there's a golden test framework in <code>dsl/lib/haskell/natural4/test/LS/XPile/LogicalEnglish</code> that Joe and Jo Hsi ahd worked on, and that we found helpful when developing this transpiler.</p> <p>Finally, note that some of the comments in the LE transpiler codebase are out of date / out of sync with the code. Apologies about that --- I (YM) will try to clean that up soon.</p>"},{"location":"current_system/codebase/natural4/#maude","title":"Maude","text":"<p>This was the subject of Joe's paper on the Contract as Automata work.</p> <p>https://www.researchgate.net/publication/375025000_Deontics_and_time_in_contracts_An_executable_semantics_for_the_L4_DSL</p>"},{"location":"current_system/codebase/natural4/#logging","title":"Logging","text":"<p>The <code>Intro*.hs</code> and <code>Logging.hs</code> files record a painful learning journey toward monadic logging. The goal was to allow all transpilers and all parts of the natural4 toolchain generally to be able to produce structured logging for later debug inspection.</p> <p>(Not all transpilers use this -- Meng's --- logging framework, because this framework is optimized for Meng's setup and preferences. And in any case, this kind of logging isn't really as necessary for debugging pure functions.)</p>"},{"location":"current_system/codebase/natural4/#org","title":"Org","text":"<p>In parallel with structured logging we wrote a \"transpiler to org-mode\" with a hierarchy best read in Emacs's org-mode.</p>"},{"location":"current_system/codebase/natural4/#purescript","title":"Purescript","text":"<p>The output of this transpiler is a Purescript representation of the boolstructs involved in the decision logic elements in L4 source input.</p> <p>This Purescript output is consumed by the Vue web app.</p>"},{"location":"current_system/codebase/nlg/","title":"NLG","text":"<p>This page documents the NLG system from early 2023, which is/was used by the web form generation. The main goal was to convert the conditions in the rules into questions.</p> <p>The code is in natural4/src/LS/NLP/NLG.hs, and the grammars it uses are in natural4/grammars.</p>"},{"location":"current_system/codebase/nlg/#input","title":"Input","text":"<p>The input is a spreadsheet such as the following, which has plenty of natural language in the cells.</p> \u00a7 Assessment EVERY Organisation WHICH NOT is a Public Agency UPON becoming aware a data breach may have occurred IF the data breach occurred ON 1 Feb 2022 OR \" AFTER \" MUST assess if it is a Notifiable Data Breach <p>It is parsed into the Rule datatype, where the different text fragments are parsed into different fields. So the line <code>NOT,is,a Public Agency</code> is a qualifier of the subject (<code>Organisation</code>), and because it is in that particular field, the system will parse it as a relative clause.</p> <p>The other fields have their corresponding grammatical category as well. The action <code>assess,if it\u2026</code> will be parsed as a verb phrase. The condition <code>the data breach occurred</code> is parsed as a full sentence, and if the sentence has a temporal condition (keywords <code>ON</code>, <code>AFTER</code> etc.), it's parsed into an adverbial.</p>"},{"location":"current_system/codebase/nlg/#gf-grammar","title":"GF grammar","text":"<p>The fragments are parsed with a GF grammar with the following abstract syntax.</p> <pre><code>flowchart TD\n    A[CustomSyntax\\n\u25cf Fragment of the GF RGL\\n\u25cf Ad hoc funs on top] --&gt; B[NL4Base\\n\u25cf Domain-specific\\n constructions for L4]\n    B --&gt; C[StandardLexicon\\n\u25cf Curated lexicon of\\n frequent vocabulary]\n    B --&gt; D[DomainLexicon\\n\u25cf Generated from\\n the current document\\n\u25cf Not automatic,\\njust a proof of concept!]</code></pre> <p>GF RGL is the Resource Grammar Library, which contains basic syntactic constructions for ~40 different languages. CustomSyntax takes a subset of those, and adds some specific constructions on top of it.</p> <p>These constructions were just added there by Inari based on the two example cases: PDPA and Rodents and Vermins. For example, the RGL doesn't support conjunction of prepositions like \"on or after\", so we added it into the CustomSyntax module.</p> <p>We make some assumptions about which forms the fragments appear, for example, after <code>UPON</code>, there should be a verb phrase in gerund, not a full sentence with a subject. But these assumptions haven't been written down anywhere.</p>"},{"location":"current_system/codebase/nlg/#tree-transformations-to-produce-new-natural-language","title":"Tree transformations to produce new natural language","text":"<p>After the different fields are parsed into GF trees, we can take their constituents and transform them into different trees.</p> <p>The most successful application has been creating questions for the web form. For instance, <code>UPON,becoming aware that a data breach may have occurred</code> would become a question \"have you become aware that a data breach may have occurred\". We can assume that the subject is you, i.e. the person filling the web form. This is nice, because each of the conditions needs to be fulfilled in order for the whole rule to hold, and they get their own individual questions as full sentences.</p> <p>There has always been the goal to create a full document from the spreadsheet version. Some prototypes have existed, but their problem has been that the sentences become very long. I (Inari) personally think that the original spreadsheet form is more readable, because it uses indentation and linebreaks. So if (/when) we want to create a full plain English document from the spreadsheet, we'll need to do something smarter than just concatenate the subtrees into larger trees.</p>"},{"location":"current_system/codebase/nlg/#lexicon-generation","title":"Lexicon generation","text":"<p>We (Maryam and Inari) also did some smaller experiments in generating the lexicon automatically, using an external parser via the Python NLP library spaCy. Probably the most up-to-date version of the code that generates GF lexica is here in Inari's sandbox.</p> <p>It was surprisingly good for getting the valencies of the verbs, but there was still a substantial amount of manual checking and correction needed. But given that the next use case didn't use the web app, this system was never needed in practice.</p> <p>We also never automated the pipeline.</p>"},{"location":"current_system/codebase/nlg/#status","title":"Status","text":"<p>The current code and grammar are deprecated, but I (Inari) believe that there are ideas that are worth to salvage and develop further.</p>"},{"location":"current_system/codebase/nlg/#future-goals","title":"Future goals","text":""},{"location":"current_system/codebase/nlg/#curated-lexicon","title":"Curated lexicon","text":"<p>Actually create a large curated lexicon (the module <code>StandardLexicon</code> in the graph). It should have at least some thousands of words, and probably in several modules, divided in subdomains.</p>"},{"location":"current_system/codebase/nlg/#cnl","title":"CNL","text":"<p>Make the natural language in the cells more controlled. For instance, we could revisit Meng's \"prepositional logic\", like the example below.</p> eat noodles with chopsticks at noon <p>Unlike the all caps keywords of L4, should we have natural language keywords that we treat in a specific way when parsing?</p>"},{"location":"current_system/codebase/rule_ast/","title":"AST (or CST?) for rules","text":""},{"location":"current_system/codebase/rule_ast/#rule","title":"Rule","text":"<p>The data type for Rule is defined in dsl/\u2026/Rule.hs.</p> <p>It has the following constructors:</p> <pre><code>-- The most commonly used\nRegulative\nConstitutive\nHornlike\n\n-- For defining types and their fields\nTypeDecl\n\n-- Haven't seen these used much\nScenario\nDefNameAlias\nDefTypically\n\n-- internal softlink to a rule label (rlabel), e.g. HENCE NextStep\nRuleAlias\n-- a list of rules + a named section heading\nRuleGroup\n\n-- I guess these are like default rules?\nRegFulfilled\nRegBreach\n\n-- not a rule  \u00af\\_(\u30c4)_/\u00af\nNotARule\n</code></pre>"},{"location":"current_system/codebase/rule_ast/#boolstruct","title":"BoolStruct","text":"<p>There's another library called <code>anyall</code>, which defines a datatype called BoolStruct.</p> <pre><code>data BoolStruct lbl a\n  = Leaf a\n  | All lbl [BoolStruct lbl a] -- and\n  | Any lbl [BoolStruct lbl a] --  or\n  | Not (BoolStruct lbl a)\n  deriving (Eq, Ord, Show, Generic, Hashable, FromJSON, ToJSON, Functor, Foldable, Traversable)\n</code></pre> <p><code>BoolStructR</code> is a BoolStruct with an optional label (<code>Maybe Text</code>) and a <code>RelationalPredicate</code>.</p>"},{"location":"current_system/codebase/rule_ast/#relationalpredicate","title":"RelationalPredicate","text":"<pre><code>data RelationalPredicate =\n    RPParamText   ParamText                     -- cloudless blue sky\n  | RPMT MultiTerm  -- intended to replace RPParamText. consider TypedMulti?\n  | RPConstraint  MultiTerm RPRel MultiTerm     -- eyes IS blue\n  | RPBoolStructR MultiTerm RPRel BoolStructR   -- eyes IS (left IS blue AND right IS brown)\n  | RPnary RPRel [RelationalPredicate] -- \"NEVER GO FULL LISP!\" \"we went full Lisp\".\n</code></pre>"},{"location":"current_system/codebase/rule_ast/#types-for-values","title":"Types for values","text":"<p>The base for all types is the <code>MTExpr</code> type.</p> <pre><code>data MTExpr = MTT Text.Text -- ^ Text string\n            | MTI Integer   -- ^ Integer\n            | MTF Double     -- ^ Float\n            | MTB Bool      -- ^ Boolean\n\ntype MultiTerm = [MTExpr]\n\ntype TypedMulti = (NonEmpty MTExpr, Maybe TypeSig)\n\ntype ParamText = NonEmpty TypedMulti\n</code></pre>"},{"location":"current_system/codebase/rule_ast/#types-for-types","title":"Types for types","text":"<pre><code>data TypeSig = SimpleType ParamType EntityType\n             | InlineEnum ParamType ParamText\n\ndata ParamType = TOne | TOptional | TList0 | TList1 | TSet0 | TSet1\n\ntype EntityType = Text.Text\n</code></pre>"},{"location":"current_system/codebase/rule_ast/#rprel","title":"RPRel","text":"<p>The list of <code>RPRel</code>s is as follows.</p> <pre><code>data RPRel =\n    RPis | RPhas\n  | RPeq | RPlt | RPlte | RPgt | RPgte\n  | RPelem | RPnotElem\n  | RPnot | RPand | RPor\n  | RPmap\n  | RPmin | RPmax\n  | RPsum | RPproduct | RPminus | RPdivide | RPmodulo\n  | RPTC TComparison\n\ndata TComparison = TBefore | TAfter | TBy | TOn | TVague\n</code></pre>"},{"location":"current_system/codebase/rule_ast/#redundancies-in-relationalpredicate","title":"Redundancies in RelationalPredicate","text":""},{"location":"current_system/codebase/rule_ast/#paramtext-and-multiterm","title":"ParamText and MultiTerm","text":"<pre><code>    RPParamText   ParamText\n  | RPMT          MultiTerm\n</code></pre> <p>Both ParamText and MultiTerm are based on a list of <code>MTExpr</code>. ParamText has in addition an optional TypeSig attached to the expressions and two separate NonEmpty lists.</p> <p>So in translation to Generic MathLang, I just do this</p> <pre><code>case rp of\n  RPParamText pt -&gt; expifyBodyRP $ RPMT $ pt2multiterm pt\n  RPMT mtes -&gt; expifyMTEsNoMd mtes\n</code></pre>"},{"location":"current_system/codebase/rule_ast/#logical-operators-from-rprel-and-boolstruct","title":"Logical operators from RPRel and BoolStruct","text":"<p>The type <code>RPRel</code> contains logical operators <code>RPnot</code>, <code>RPand</code>, <code>RPor</code>. So these things can be in the BoolStructR, or inside the RelationalPredicate.</p> <pre><code>Leaf (RPnary RPnot [rp])\n-- should be the same as\nNot (Leaf rp)\n\nLeaf (RPnary RPall [rp1, rp2])\n-- should be the same as\nAll lbl [Leaf rp1, Lea rp2]\n</code></pre> <p>The difference is that the BoolStruct constructors <code>Any</code> and <code>All</code> include a label (which for BoolStructR is Maybe Text). Maybe there's also some other differences that I'm not aware of?</p>"},{"location":"current_system/codebase/visualizations/","title":"Visualizations","text":"<p>A handful of components produce visualizations of L4 expressions.</p>"},{"location":"current_system/codebase/visualizations/#simple-ladder-svgs","title":"simple ladder SVGs","text":"<p>In 2020, simple Boolean-only decision logic was visualized with a library inspired by ladder logic Boolean circuit diagrams. See the original specification in Google Drive</p> <p>The tiny versions show up in the sidebar and look like this.</p> <p></p> <p>The fuller versions contain text and look like this.</p> <p></p> <p>See also <code>SVGLadder.hs</code> in AnyAll</p>"},{"location":"current_system/codebase/visualizations/#interactive-ladder-html","title":"interactive ladder HTML","text":"<p>Subsequently, interns Jules and Zeming wrote an interactive version in HTML.</p> <p>This draws the interactive, clickable diagrams at the bottom of the web interview.</p> <ul> <li>smucclaw/ladder-diagram repo</li> <li>There are also docs available for this, via</li> </ul> <pre><code>npm install jsdoc -g\nnpm run docs\n</code></pre> <ul> <li>Specification in Google Drive</li> </ul>"},{"location":"current_system/codebase/visualizations/#representation","title":"Representation","text":"<p>This represents boolean circuits with this AST. Their <code>AllQuantifier</code> name is a bit misleading: it's not \u2200.</p> <p>Atomic propositions can be True, False, or Unknown.</p>"},{"location":"current_system/codebase/visualizations/#expression-tree-explorer-mathlang-vis","title":"expression tree explorer ('mathlang vis')","text":"<p>Our redoubtable interns further wrote code to fold (show/hide) subexpressions of MathLang:</p> <p>https://github.com/smucclaw/usecases/tree/mathlang-vis-horizontal</p> <p>Video demo</p> <p>To try it out and click through the graph and fill in the questions:</p> <pre><code>npm i\nnpm run watch-ts\nnpm run start\n</code></pre>"},{"location":"current_system/codebase/visualizations/#representation_1","title":"Representation","text":"<p>Boolean logic with arithmetic and exceptions.</p> <p>See the AST.</p> <p>The <code>MathlangVis</code> class renders this tree by converting each <code>NodeTemplate</code> into HTML elements.</p> <p>Visualization is coupled with evalaution in this project.</p>"},{"location":"current_system/codebase/visualizations/#petri-net-stuff","title":"Petri Net stuff","text":"<p>https://github.com/smucclaw/dsl/blob/main/lib/haskell/natural4/src/LS/XPile/Petri.hs</p> <p>According to Meng (16 May 2024):</p> <ul> <li>Context: This was meant to be a visualization for the state transition parts / deontics-handling parts of L4.</li> <li>Status: Although we still want to offer visualizations for the state transition-y parts in the next iteration of L4,  we don't need to stick to Petri Nets. We are free to move to something else, if there are better alternatives.</li> <li>Prior Art: one of the earliest papers in the field of computable contracts, Ronald Lee 1998, chose the Petri Net formalism.</li> </ul>"}]}